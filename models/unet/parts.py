import torch
import torch.nn as nn
import torch.nn.functional as F

class DoubleConv(nn.Module) :
    '''
    Double Convolution and BN and ReLU
    (3x3 conv -> BN -> ReLU) ** 2
    '''
    def __init__(self, in_ch, out_ch) :
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, kernel_size = 3, padding = 1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace = True),
            nn.Conv2d(out_ch, out_ch, kernel_size = 3, padding = 1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace = True)
        )
        
    def forward(self, x) :
        return self.net(x)
    
class Down(nn.Module) :
    '''
    Combination of MaxPool2d and DoubleConv in series
    '''
    def __init__(self, in_ch, out_ch) : 
        super().__init__()
        self.net = nn.Sequential(
            nn.MaxPool2d(kernel_size = 2, stride = 2),
            DoubleConv(in_ch, out_ch)
        )
        
    def forward(self, x) :
        return self.net(x)
    
class Up(nn.Module) :
    '''
    Upsampling (by either bilinear interpolation or transpose convolutions) 
    followed by concatenation of feature map from contracting path, 
    followed by double 3x3 convolution.
    '''
    def __init__(self, in_ch, out_ch, bilinear = False) :
        super().__init__()
        self.upsample = None
        if bilinear :
            self.upsample = nn.Upsample(scale_factor = 2, mode = 'bilinear', align_corners = True)
        else : 
            self.upsample = nn.ConvTranspose2d(in_ch, in_ch // 2, kernel_size = 2, stride = 2)
            
        self.conv = DoubleConv(in_ch, out_ch)
        
    def forward(self, x1, x2) :
        x1 = self.upsample(x1)
        
        # Pad x1 to the size of x2
        diff_h = x2.shape[2] - x1.shape[2]
        diff_w = x2.shape[3] - x1.shape[3]
        
        x1 = F.pad(x1, [diff_w // 2, diff_w - diff_w // 2, diff_h // 2, diff_h - diff_h // 2])
        
        # Concatenate along the channels axis
        x = torch.cat([x2, x1], dim = 1)
        return self.conv(x)